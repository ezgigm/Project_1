{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grabbing Budget&Revenue Values from 'the-numbers.com'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need budget values for top rates films.\n",
    "We grabbed them with web scrabing by using Beautiful Soap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd                #import pandas and numpy for dataframe and series\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup      #import request and Beautiful Soap for "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grabbing the first page of list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First page of the list URL finishes with /all so we took this value independently.\n",
    "\n",
    "For other pages we create new for loop according to pattern of webpages URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.the-numbers.com/movie/budgets/all\"\n",
    "res = requests.get(url)                               #Assign URL to res for Beautiful Soap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(res.text)             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup                 #to see the results and find the class which we need\n",
    "#we understood from values the class we need is 'tr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = soup.findAll('tr')          #Assign class values to our movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dates = []           #create empty list for dates\n",
    "names = []           #create empty list for names\n",
    "budget = []          #create empty list for budget\n",
    "domestic_gross = []  #create empty list for domestic gross\n",
    "ww_gross = []        #create empty list for worldwide gross\n",
    "\n",
    "for i in list(range(1, 101)):\n",
    "    dates.append((movies[i].findAll('td')[1].string))\n",
    "    names.append((movies[i].findAll('td')[2].string))\n",
    "    budget.append((movies[i].findAll('td')[3].string))\n",
    "    domestic_gross.append((movies[i].findAll('td')[4].string))\n",
    "    ww_gross.append((movies[i].findAll('td')[5].string))\n",
    "    \n",
    "#this for loop takes our necessary values from 'td' class and assign new list\n",
    "\n",
    "df = pd.DataFrame(list(zip(dates, names,budget,domestic_gross,ww_gross)), \n",
    "               columns =['Date', 'Name','Budget','Domestic Gross','WW_Gross']) \n",
    "df #to see our new dataframe for page 1\n",
    "\n",
    "#Assign our values to df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grabbing other pages values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We figured out that there is a pattern at the end of the URL for each page.\n",
    "\n",
    "So, we created new list as my_list according to pattern of the URL's end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 101,  201,  301,  401,  501,  601,  701,  801,  901, 1001, 1101,\n",
       "       1201, 1301, 1401, 1501, 1601, 1701, 1801])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_list = np.arange(101,1901,100)\n",
    "my_list         # my array according to page URL pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame([])          #create a dataframe for my new combined pages\n",
    "\n",
    "for index in my_list :  \n",
    "    url_1 = f\"https://www.the-numbers.com/movie/budgets/all/{index}\"#index is taking from page which ends 101 to 1801\n",
    "    res = requests.get(url_1)\n",
    "    soup = BeautifulSoup(res.text)\n",
    "    movies_1 = soup.findAll('tr')\n",
    "#create empty lists for new values\n",
    "    dates_1 = []\n",
    "    names_1 = []               \n",
    "    budget_1= []\n",
    "    domestic_gross_1 = []\n",
    "    ww_gross_1 = []\n",
    "\n",
    "    for a_1 in list(range(1, 101)):\n",
    "        dates_1.append((movies_1[a_1].findAll('td')[1].string))\n",
    "        names_1.append((movies_1[a_1].findAll('td')[2].string))\n",
    "        budget_1.append((movies_1[a_1].findAll('td')[3].string))\n",
    "        domestic_gross_1.append((movies_1[a_1].findAll('td')[4].string))\n",
    "        ww_gross_1.append((movies_1[a_1].findAll('td')[5].string))\n",
    "\n",
    "\n",
    "    df_1 = pd.DataFrame(list(zip(dates_1, names_1,budget_1,domestic_gross_1,ww_gross_1)), \n",
    "               columns =['Date', 'Name','Budget','Domestic Gross','WW_Gross']) \n",
    "    data = pd.DataFrame.append(data,df_1) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.tail()  #to see the last values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging the first page and other pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_concat = [df, data]\n",
    "combined_df = pd.concat(to_concat)\n",
    "#to merge the first URL and others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.tail()  #to see the tail of the combined dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.reset_index() #to reset index before converting to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.to_csv('1900movies_budget_domesticgross_WW_gross.csv') #write them to csv after that we use this csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
